{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":67356,"databundleVersionId":8006601,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kartikeybartwal/creating-new-medicines-using-biobert-and-belka?scriptVersionId=185694173\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-27T07:27:10.612052Z","iopub.execute_input":"2024-06-27T07:27:10.612411Z","iopub.status.idle":"2024-06-27T07:27:10.620588Z","shell.execute_reply.started":"2024-06-27T07:27:10.612384Z","shell.execute_reply":"2024-06-27T07:27:10.619623Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"/kaggle/input/leash-BELKA/sample_submission.csv\n/kaggle/input/leash-BELKA/train.parquet\n/kaggle/input/leash-BELKA/test.parquet\n/kaggle/input/leash-BELKA/train.csv\n/kaggle/input/leash-BELKA/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-06-27T07:27:10.622311Z","iopub.execute_input":"2024-06-27T07:27:10.622569Z","iopub.status.idle":"2024-06-27T07:27:10.63161Z","shell.execute_reply.started":"2024-06-27T07:27:10.622545Z","shell.execute_reply":"2024-06-27T07:27:10.63085Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"!pip install rdkit\n'''\nRDKit, an open-source cheminformatics tool, is used for generating ECFP features.\nIt facilitates the creation of hashed bit vectors, streamlining the process\n'''","metadata":{"execution":{"iopub.status.busy":"2024-06-27T07:27:10.632648Z","iopub.execute_input":"2024-06-27T07:27:10.632928Z","iopub.status.idle":"2024-06-27T07:27:12.881026Z","shell.execute_reply.started":"2024-06-27T07:27:10.632905Z","shell.execute_reply":"2024-06-27T07:27:12.87998Z"},"trusted":true},"execution_count":104,"outputs":[{"name":"stdout","text":"Requirement already satisfied: rdkit in /opt/conda/lib/python3.10/site-packages (2024.3.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rdkit) (1.26.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from rdkit) (9.5.0)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"'\\nRDKit, an open-source cheminformatics tool, is used for generating ECFP features.\\nIt facilitates the creation of hashed bit vectors, streamlining the process\\n'"},"metadata":{}}]},{"cell_type":"code","source":"!pip install duckdb\n\n'''\nWe have a large training set, and we can consider the parquet files as\ndatabases by using duckdb. We'll use this approach to create a smaller\ndataset for demonstration purposes.\n'''","metadata":{"execution":{"iopub.status.busy":"2024-06-27T07:27:12.883358Z","iopub.execute_input":"2024-06-27T07:27:12.883668Z","iopub.status.idle":"2024-06-27T07:27:16.988807Z","shell.execute_reply.started":"2024-06-27T07:27:12.883637Z","shell.execute_reply":"2024-06-27T07:27:16.987835Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"Requirement already satisfied: duckdb in /opt/conda/lib/python3.10/site-packages (1.0.0)\n^C\n\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"\"\\nWe have a large training set, and we can consider the parquet files as\\ndatabases by using duckdb. We'll use this approach to create a smaller\\ndataset for demonstration purposes.\\n\""},"metadata":{}}]},{"cell_type":"code","source":"'''\nWe utilize duckdb to scan through the large training sets. To begin,\nwe'll sample an equal number of positive and negative samples. \nThe query selects 30,000 samples where \"binds\" equals both 0 and 1.\n'''","metadata":{"execution":{"iopub.status.busy":"2024-06-27T07:27:16.990087Z","iopub.execute_input":"2024-06-27T07:27:16.99038Z","iopub.status.idle":"2024-06-27T07:27:16.996685Z","shell.execute_reply.started":"2024-06-27T07:27:16.99035Z","shell.execute_reply":"2024-06-27T07:27:16.995641Z"},"trusted":true},"execution_count":106,"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"'\\nWe utilize duckdb to scan through the large training sets. To begin,\\nwe\\'ll sample an equal number of positive and negative samples. \\nThe query selects 30,000 samples where \"binds\" equals both 0 and 1.\\n'"},"metadata":{}}]},{"cell_type":"code","source":"import duckdb\nimport pandas as pd\n\ntrain_path = '/kaggle/input/leash-BELKA/train.parquet'\ntest_path = '/kaggle/input/leash-BELKA/test.parquet'","metadata":{"execution":{"iopub.status.busy":"2024-06-27T07:27:16.997793Z","iopub.execute_input":"2024-06-27T07:27:16.998151Z","iopub.status.idle":"2024-06-27T07:27:17.009113Z","shell.execute_reply.started":"2024-06-27T07:27:16.998118Z","shell.execute_reply":"2024-06-27T07:27:17.008256Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"con = duckdb.connect()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T07:27:17.010108Z","iopub.execute_input":"2024-06-27T07:27:17.010367Z","iopub.status.idle":"2024-06-27T07:27:17.032063Z","shell.execute_reply.started":"2024-06-27T07:27:17.010344Z","shell.execute_reply":"2024-06-27T07:27:17.031275Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"df = con.query(f\"\"\"(SELECT *\n                        FROM parquet_scan('{train_path}')\n                        WHERE binds = 0\n                        ORDER BY random()\n                        LIMIT 30000)\n                        UNION ALL\n                        (SELECT *\n                        FROM parquet_scan('{train_path}')\n                        WHERE binds = 1\n                        ORDER BY random()\n                        LIMIT 30000)\"\"\").df()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T07:27:17.033007Z","iopub.execute_input":"2024-06-27T07:27:17.033291Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89abf3482d164204bf83fa2a14ea1f87"}},"metadata":{}}]},{"cell_type":"code","source":"con.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ","metadata":{}},{"cell_type":"code","source":"''' \nPRINTS THE TOP 3 LONGEST COMPOUNDS AND THE LAST 3 SMALLEST COMPOUNDS\n'''\n\ndef print_top_and_bottom_lengths(df, column_name):\n    if column_name not in df.columns:\n        print(f\"Column '{column_name}' does not exist in the DataFrame.\")\n        return\n\n    df['length'] = df[column_name].apply(len)\n    sorted_df = df.sort_values(by='length', ascending=False)\n    top_5 = sorted_df.head(5)\n    bottom_5 = sorted_df.tail(5)\n\n    print(\"Top 5 elements with the highest length:\")\n    print(top_5[[column_name, 'length']])\n\n    print(\"\\nLast 5 elements with the smallest length:\")\n    print(bottom_5[[column_name, 'length']])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nFUNCTION THAT PLOTS THE TOP 3 HIGHEST AND THE LAST 3 LOWEST FREQUENCY \nCOMPOUNDS \n'''\n\ndef plot_top_and_bottom_values(df, col_name):\n    value_counts = df[col_name].value_counts()\n    top_3 = value_counts.head(3)\n    last_3 = value_counts.tail(3)\n    \n    combined = pd.concat([top_3, last_3]).reset_index()\n    combined.columns = [col_name, 'counts']\n\n    combined[col_name] = combined[col_name].str.upper()\n\n    plt.figure(figsize=(14, 7))\n    sns.barplot(x=col_name, y='counts', data=combined, palette='viridis')\n\n    plt.title(f'Value Counts of {col_name.upper()} (Top 3 and Last 3)')\n    plt.xlabel(f'{col_name.upper()}')\n    plt.ylabel('COUNTS')\n\n    plt.xticks(rotation=45)\n\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### buildingblock1_smiles","metadata":{}},{"cell_type":"code","source":"df[\"buildingblock1_smiles\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplot_top_and_bottom_values(df, \"buildingblock1_smiles\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_top_and_bottom_lengths(df , \"buildingblock1_smiles\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### buildingblock2_smiles","metadata":{}},{"cell_type":"code","source":"df[\"buildingblock2_smiles\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_top_and_bottom_values(df, \"buildingblock2_smiles\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_top_and_bottom_lengths(df , \"buildingblock2_smiles\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### buildingblock3_smiles","metadata":{}},{"cell_type":"code","source":"df[\"buildingblock3_smiles\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_top_and_bottom_values(df, \"buildingblock3_smiles\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_top_and_bottom_lengths(df , \"buildingblock3_smiles\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### molecule_smiles","metadata":{}},{"cell_type":"code","source":"df[\"molecule_smiles\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_top_and_bottom_values(df, \"molecule_smiles\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_top_and_bottom_lengths(df , \"molecule_smiles\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### protein_names","metadata":{}},{"cell_type":"code","source":"df[\"protein_name\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams.update({'font.size': 14, 'font.weight': 'bold'})\nprotein_counts = df[\"protein_name\"].value_counts()\nplt.figure(figsize=(10, 8))\nprotein_counts.plot(kind=\"pie\", autopct=\"%1.1f%%\", startangle=90)\nplt.axis(\"equal\")\nplt.title(\"Protein Name Distribution\")\nplt.ylabel(\"\")  \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Binds","metadata":{}},{"cell_type":"code","source":"df[\"binds\"].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.countplot(data=df, x='binds')\nplt.title('Count of Binds')\nplt.xlabel('Binds')\nplt.ylabel('Count')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"from rdkit import Chem\nfrom rdkit.Chem import AllChem\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import average_precision_score\nfrom sklearn.preprocessing import OneHotEncoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CONVERT SMILES TO RDkit MOLECULES\ndf['molecule'] = df['molecule_smiles'].apply(Chem.MolFromSmiles)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate ECFPs\ndef generate_ecfp(molecule, radius=2, bits=1024):\n    if molecule is None:\n        return None\n\n    # Suppress deprecation warning (use with caution)\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n        return list(Chem.AllChem.GetMorganFingerprintAsBitVect(molecule, radius, nBits=bits))  # Enclose the triggering line\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate ECFPs\ndef generate_ecfp(molecule, radius=2, bits=1024):\n    if molecule is None:\n        return None\n\n    # Suppress deprecation warning (use with caution)\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n        return list(Chem.AllChem.GetMorganFingerprintAsBitVect(molecule, radius, nBits=bits))  # Enclose the triggering line\n\npd.options.mode.chained_assignment = None  # default='warn'\ndf['ecfp'] = df['molecule'].apply(generate_ecfp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One-hot encode the protein_name\nonehot_encoder = OneHotEncoder(sparse_output=False)\nprotein_onehot = onehot_encoder.fit_transform(df['protein_name'].values.reshape(-1, 1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine ECFPs and one-hot encoded protein_name\nX = [ecfp + protein for ecfp, protein in zip(df['ecfp'].tolist(), protein_onehot.tolist())]\ny = df['binds'].tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Building (Using ARTIFICIAL NEURAL NETWORK AND KERAS-TUNER) ","metadata":{}},{"cell_type":"code","source":"# Split the data into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install keras_tuner","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### This smodel will output the probability percentages. \n#### After getting the best model architecture and building it we will be adjusting the threshold value for the best accuracy with respect to training and testing data ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\n# Verify GPU is available\nif len(tf.config.experimental.list_physical_devices('GPU')) > 0:\n    print(\"GPU is available and will be used for training.\")\nelse:\n    print(\"GPU is not available, using CPU.\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}